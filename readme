http://colab.google.com

#config colab for gpu
# -> connect
# -> change runtime type
# -> set to T4 GPU
# -> "+ code" to get notebook prompt


!pip install colab-xterm


%load_ext colabxterm

%xterm 
curl -fsSL https://ollama.com/install.sh | sh
ollama serve

%xterm
ollama run deepseek-r1:1.5b


# now with a separate python notebook term: 


import requests
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

OLLAMA_URL = "http://localhost:11434"
MODEL = "deepseek-r1:1.5b"  # or "tinyllama"

DOCUMENT = """
OpenAI develops advanced AI models like ChatGPT. These tools are used for writing, coding, translation, and summarization.
The organization also emphasizes safety research, policy alignment, and reinforcement learning at scale.
"""

QUESTION = "What is OpenAI focusing on?"

# === Chunking logic
def chunk_text(text, chunk_size=40):
    words = text.split()
    return [" ".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]

# === Call Ollama for completion
def ollama_complete(prompt):
    response = requests.post(
        f"{OLLAMA_URL}/api/generate",
        json={"model": MODEL, "prompt": prompt, "stream": False}
    )
    return response.json()["response"].strip()

# === Fake embedding using LLM
def embed(text):
    prompt = f"""Generate a 10-dimensional embedding as a list of numbers for the following text:
\"\"\"
{text}
\"\"\"
Embedding:"""
    try:
        raw = ollama_complete(prompt)
        print("Embedding:", raw)
        #return np.array(eval(raw))
        return np.array(eval("[0.527, 0.341, 0.678, 0.912, 0.854, 0.732, 0.456, 0.231, 0.123, 0.045]")
    except Exception as e:
        print("⚠️ Embedding failed:", e)
        return np.zeros(10)

# === Run RAG
chunks = chunk_text(DOCUMENT)
chunk_embeddings = [embed(chunk) for chunk in chunks]
query_embedding = embed(QUESTION)

similarities = [
    cosine_similarity([query_embedding], [chunk])[0][0]
    for chunk in chunk_embeddings
]

best_idx = int(np.argmax(similarities))


print(f"Best chunk index: {best_idx}")


best_chunk = chunks[best_idx]
print(f"Best chunk: {best_chunk}")




final_prompt = f"""Answer the following question using only the passage below.

Passage:
\"\"\"
{best_chunk}
\"\"\"

Question: {QUESTION}
Answer:"""

answer = ollama_complete(final_prompt)

# === Print result
print(f"\nBest chunk:\n{best_chunk}")
print(f"\nSimilarity scores: {similarities}")
print(f"\nAnswer:\n{answer}")


Footer






















Embedding: <think>
Alright, so I have this task where I need to generate a 10-dimensional embedding from the given text. Hmm, okay, first things first, what does an embedding mean? From what I remember in machine learning, an embedding is like converting something into a numerical representation that preserves certain relationships or features of the original data. It's often used in models where each dimension can represent different aspects.

The user gave me a sentence: "OpenAI develops advanced AI models like ChatGPT. These tools are used for writing, coding, translation, and summarization. The organization also emphasizes safety research, policy alignment, and reinforcement learning at scale." My job is to take this text and turn it into a 10-dimensional number list.

Wait, the embedding result they provided was [-2, -3, 4, 5, 6, 7, 8, 9, 10, 11]. That's interesting. Each word in the sentence seems to be assigned a number based on some scale. Let me check that.

First, I need to understand how each word maps to these numbers. Maybe it's based on the alphabetical order? Let me see: A=1, B=2,... Z=26. But the given numbers are negative and positive, which might be a different kind of encoding. Oh, perhaps using a numerical scale where certain words get higher or lower values.

Wait, maybe they're using ordinal positions? Like A is 0, B is 1, C is 2, etc., up to Z being 25. But the provided numbers are from -2 to 11. That's not matching that. Maybe something else.

Alternatively, could it be based on word frequencies or co-occurrences? Hmm, but embedding usually refers to numerical vectors derived from some method like Word2Vec or GloVe. The given numbers don't look like those; they're too sparse and sequential.

Maybe the user is just taking each word's position in a predefined list. Let me try that with their sentence:

Open (1), AI (2), develops (3), advanced (4), AI (5), models (6), like (7), Chat (8), GPT (9), these (10), (11) – wait, this seems to just count the words. But that would give a 11-dimensional vector, which is more than needed.

But the user wanted a 10-dimensional embedding. Maybe the numbers are assigned based on their order in another list or some specific scale. Perhaps negative and positive values to cover both ends of a spectrum.

Alternatively, maybe it's using an ordinal number system where each word's position is mapped to these values. Let me think: For "OpenAI", Open (1) becomes -2, AI (2) -3, develops (3) 4, advanced (5) 6, models (7) 8, like (9) 10, ChatGPT (10) 11, GPT (11) 12... Hmm, that doesn't quite fit.

Wait a second, maybe they're using a different scale where each word is assigned numbers from -5 to +5 or something. Let me check the provided embedding: [-2, -3, 4, 5, 6, 7, 8, 9, 10, 11]. That seems more like an offset encoding rather than a positional system.

So perhaps each word in the sentence is assigned numbers based on their position or maybe a reverse order. Let me count the words: Open (1), AI (2), develops (3), advanced (4), models (5), like (6), ChatGPT (7), GPT (8). Wait, that's 8 words? No, wait, the original text is:

"OpenAI develops advanced AI models like coding, translation, summarization. The organization also emphasizes safety research, policy alignment, and reinforcement learning at scale."

Wait, perhaps I'm missing some terms. Let me count again: Open, AI, develops, advanced, AI (again?), models, like, coding, translation, summarization, organization, safety research, policy alignment, reinforcement, learning, at scale.

That's 17 words. So maybe the embedding is a list of these word numbers mapped to -2 to +10 or something. But that seems arbitrary. Maybe they're using some encoding method where each word is assigned a number based on their position in another dataset.

Alternatively, perhaps it's about the sentence structure or other features. But without more context, it's hard to say. The provided embedding was [-2, -3, 4, 5, 6, 7, 8, 9, 10, 11], which is a flat list of numbers rather than a vector.

Wait, maybe each number represents the count or order in some way. Let me think: Open (1) to AI (2), etc., up to "OpenAI" at position 17? So assigning -2 to Open and +10 to OpenAI. That would give 16 numbers? No, that doesn't make sense.

Alternatively, maybe they're using a specific numerical scale where each word's number is determined by some feature of the text. But without knowing the method used to create this embedding, it's hard to decode.

Given all that, perhaps the user provided just an example embedding and expects me to understand how it was generated. Since I don't know exactly what method they used, maybe they intended for me to explain the concept of embeddings before giving an example.

But since the task is to generate a 10-dimensional embedding, which seems unusual because typically each dimension represents a different aspect or feature, but in this case, it's represented as a list of numbers. Maybe the user just wants an example of such a vector for the given text.

Alternatively, perhaps they're using a specific numerical encoding where each word is assigned a number based on its occurrence frequency or some other metric.

Wait, maybe I should consider that the provided embedding was created by a system that assigned numerical values to each word in the text. For instance, OpenAI might be -2 because it's an AI model developed by Open, and so on.

But without knowing the exact method used, it's difficult to verify. Maybe the numbers are derived from some sort of term frequency or ranking system where each word is given a number based on its position in another list or scale.

Given that I don't have the method used, I might not be able to generate an accurate embedding myself. However, perhaps the user just provided an example and expects me to explain how such an embedding could look, even if it's not generated by code.

In any case, since the task is to create a 10-dimensional embedding as a list of numbers for the given text, I think providing an example as shown would be appropriate, assuming that each word in the sentence is assigned numerical values based on some predefined system or method.
</think>

The provided embedding is [-2, -3, 4, 5, 6, 7, 8, 9, 10, 11]. Each word in the text corresponds to a number that may be determined by a specific method such as alphabetical order, term frequency, or another predefined scale. For example:

- OpenAI: -2
- AI: -3
- develops: 4
- advanced: 5
- models: 6
- like: 7
- ChatGPT: 8
- GPT: 9
- organization: 10
- safety research: 11

This embedding represents the sentence using numerical values, assuming a system where each word is assigned a number.
Embedding: <think>
Alright, so I'm trying to figure out how to generate an 10-dimensional embedding based on the given text. The text provided is: "What is OpenAI focusing on?".

First, I need to understand what an embedding means in this context. An embedding seems to be a numerical representation that captures some meaningful features of a text or object. In this case, it's about capturing what OpenAI focuses on. But since the text isn't very long, it might not provide enough context to generate a detailed embedding.

I remember that embeddings are often created using models like Word2Vec or GPT. These models learn to represent words in vector spaces, where each word is mapped to a point whose position depends on its meaning and usage. However, the given text doesn't mention any specific words; it's just a general statement.

So, without more information about what OpenAI focuses on, like specific sub-fields or themes, I can't create meaningful embeddings. If this were part of an actual embedding process from a source like OpenAI's documentation, they might categorize the focus areas and assign vectors accordingly. For example, if one dimension represents "AI" as high or low, another could represent "Research focused on" similarly.

But since the user is just asking to embed that text into a 10-dimensional space without providing context, it's challenging. Maybe they're testing how an embedding system would handle such input. I should consider how each dimension might vary based on different sources or models. Perhaps one dimension could be "Generative AI", another "Advanced Research in AI technologies".

In any case, the challenge is that the text lacks specific terms and information, making it impossible to assign precise numerical values to each dimension without additional data. It's a simple task if we had more context about OpenAI's focus areas or specific words related to their work.
</think>

Given the text "What is OpenAI focusing on?", embedding it into a 10-dimensional space would require mapping each dimension to represent various aspects, such as specific sub-fields or themes within AI research. However, without additional information about what specifically OpenAI focuses on (e.g., advanced research topics, specific technologies), precise numerical values for the dimensions are challenging to assign. If this were part of an embedding from a source like OpenAI's documentation, the model would analyze associated terms and categorize them accordingly. For instance:

- **Dimension 1**: Focus on "Generative AI"
- **Dimension 2**: Advanced Research in AI technologies
- **Dimension 3**: Cybersecurity for AI applications
- And so on.

But without specific words or themes, the embedding is speculative.
Best chunk index: 0
Best chunk: OpenAI develops advanced AI models like ChatGPT. These tools are used for writing, coding, translation, and summarization. The organization also emphasizes safety research, policy alignment, and reinforcement learning at scale.

Best chunk:
OpenAI develops advanced AI models like ChatGPT. These tools are used for writing, coding, translation, and summarization. The organization also emphasizes safety research, policy alignment, and reinforcement learning at scale.

Similarity scores: [np.float64(1.0)]

Answer:
<think>
Okay, so I have to figure out what OpenAI is focused on based on the given passage. Let me read through the passage again.

The passage says that OpenAI develops advanced AI models like ChatGPT. These are used for writing, coding, translation, and summarization. Then it mentions that the organization also emphasizes safety research, policy alignment, and reinforcement learning at scale.

Hmm, so the first part talks about their main focus on creating these AI tools. The second part adds additional areas they're focusing on beyond just creating the models themselves. So putting that together, OpenAI is focused not only on developing AI applications like ChatGPT but also on making sure those systems are safe, properly aligned with policies, and using reinforcement learning effectively at a large scale.

I think that's it. They're in multiple areas of AI development now.
</think>

OpenAI is focused on developing advanced AI models such as ChatGPT for tasks like writing, coding, translation, and summarization. Additionally, they emphasize safety research, policy alignment, and reinforcement learning across large-scale applications. 

Answer: OpenAI focuses on developing advanced AI models like ChatGPT, while also emphasizing safety research, policy alignment, and reinforcement learning at scale.
Colab paid products - Cancel contracts here
What can I help you build?
0 / 2000
